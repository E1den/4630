{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.p1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b3vRp5JP-M3",
        "colab_type": "code",
        "outputId": "db37adf8-ffb7-4750-a72e-f7bb4ad719a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import math\n",
        "#For the connected regions\n",
        "from scipy.ndimage.measurements import label\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "THRESHOLD = 0.7\n",
        "epochs = 20\n",
        "\n",
        "def getHeight(arl):\n",
        "    first = np.argmax(arl > THRESHOLD)\n",
        "    tmp = np.argmax(np.flip(arl) > THRESHOLD)\n",
        "    return math.ceil((arl.size - tmp - first)/arl.shape[1])/arl.shape[0]\n",
        "\n",
        "\n",
        "def getWidth(arl):\n",
        "    return (getHeight(np.rot90(arl))*arl.shape[0])/arl.shape[1]\n",
        "\n",
        "structure = np.ones((3, 3), dtype=np.int) * THRESHOLD\n",
        "\n",
        "print(\"Generating features\")\n",
        "\n",
        "print(\"Generating train data features\")\n",
        "for i in range(len(train_images)):\n",
        "    img = train_images[i]/255\n",
        "    #Get height\n",
        "    height = getHeight(img)\n",
        "    #Get the width\n",
        "    width = getWidth(img)\n",
        "    #Get the number of connected regions\n",
        "    _, connected = label(img, structure)\n",
        "    #Save the data in a row\n",
        "    extra = np.zeros(28)\n",
        "    extra[0] = height\n",
        "    extra[1] = width\n",
        "    if(connected == 1):\n",
        "        extra[2] = 1\n",
        "    elif(connected == 2):\n",
        "        extra[3] = 1\n",
        "    elif(connected == 3):\n",
        "        extra[4] = 1\n",
        "    else:\n",
        "        extra[5] = 1\n",
        "    #The only way for this to sort of not take forever when done this way\n",
        "    train_images[i][27] = extra\n",
        "    #if(i%500==0):\n",
        "    #   print(\"{}%\".format(int(100*i/len(train_images))))\n",
        "\n",
        "print(\"Generating test data features\")\n",
        "for i in range(len(test_images)):\n",
        "    img = test_images[i]/255\n",
        "    #Get the heights\n",
        "    height = getHeight(img)\n",
        "    #Get the widths\n",
        "    width = getWidth(img)\n",
        "    #Get the connected parts\n",
        "    _, connected = label(img, structure)\n",
        "    #Save the data in a row\n",
        "    extra = np.zeros(28)\n",
        "    extra[0] = height\n",
        "    extra[1] = width\n",
        "    if(connected == 1):\n",
        "        extra[2] = 1\n",
        "    elif(connected == 2):\n",
        "        extra[3] = 1\n",
        "    elif(connected == 3):\n",
        "        extra[4] = 1\n",
        "    else:\n",
        "        extra[5] = 1\n",
        "    #The only way for this to sort of not take forever when done this way\n",
        "    test_images[i][27] = extra\n",
        "    #if(i%500==0):\n",
        "    #    print(\"{}%\".format(int(100*i/len(test_images))))\n",
        "\n",
        "print(\"Done with features. \")\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images,\n",
        "                    train_labels,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(test_images, test_labels))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating features\n",
            "Generating train data features\n",
            "Generating test data features\n",
            "Done with features. \n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 11s 176us/sample - loss: 2.6871 - acc: 0.8843 - val_loss: 0.4235 - val_acc: 0.9138\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 10s 164us/sample - loss: 0.4088 - acc: 0.9129 - val_loss: 0.3628 - val_acc: 0.9297\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 10s 168us/sample - loss: 0.3763 - acc: 0.9184 - val_loss: 0.3256 - val_acc: 0.9384\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 11s 176us/sample - loss: 0.3646 - acc: 0.9214 - val_loss: 0.3418 - val_acc: 0.9355\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.3336 - acc: 0.9287 - val_loss: 0.3628 - val_acc: 0.9403\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 10s 163us/sample - loss: 0.3227 - acc: 0.9314 - val_loss: 0.2895 - val_acc: 0.9418\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 9s 156us/sample - loss: 0.2950 - acc: 0.9363 - val_loss: 0.3274 - val_acc: 0.9463\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 10s 161us/sample - loss: 0.3163 - acc: 0.9378 - val_loss: 0.2910 - val_acc: 0.9542\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 10s 163us/sample - loss: 0.2874 - acc: 0.9409 - val_loss: 0.3890 - val_acc: 0.9360\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 10s 162us/sample - loss: 0.2993 - acc: 0.9412 - val_loss: 0.3492 - val_acc: 0.9506\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.2728 - acc: 0.9438 - val_loss: 0.3422 - val_acc: 0.9588\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 10s 167us/sample - loss: 0.2760 - acc: 0.9448 - val_loss: 0.3736 - val_acc: 0.9501\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 10s 168us/sample - loss: 0.2783 - acc: 0.9455 - val_loss: 0.3241 - val_acc: 0.9534\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 10s 173us/sample - loss: 0.2629 - acc: 0.9479 - val_loss: 0.3912 - val_acc: 0.9566\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 11s 175us/sample - loss: 0.2651 - acc: 0.9496 - val_loss: 0.3310 - val_acc: 0.9522\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 10s 166us/sample - loss: 0.2574 - acc: 0.9485 - val_loss: 0.3951 - val_acc: 0.9527\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 10s 161us/sample - loss: 0.2540 - acc: 0.9496 - val_loss: 0.4308 - val_acc: 0.9534\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 10s 170us/sample - loss: 0.2623 - acc: 0.9508 - val_loss: 0.3401 - val_acc: 0.9522\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 10s 166us/sample - loss: 0.2360 - acc: 0.9531 - val_loss: 0.4525 - val_acc: 0.9542\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 10s 163us/sample - loss: 0.2479 - acc: 0.9527 - val_loss: 0.4204 - val_acc: 0.9566\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}